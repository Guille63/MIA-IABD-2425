{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afcea688-88b6-46ea-a926-e12770c2aaa5",
      "metadata": {
        "id": "afcea688-88b6-46ea-a926-e12770c2aaa5"
      },
      "source": [
        "# Ejercicios UD03_02.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2f1713",
      "metadata": {
        "id": "9a2f1713"
      },
      "source": [
        "## Uso de NLTK y Python\n",
        "\n",
        "* *Referencias:*\n",
        "    * *http://www.nltk.org/*\n",
        "    * *http://www.python.org/*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb",
      "metadata": {
        "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb"
      },
      "source": [
        "### a)Procesamiento del corpus cess_esp anotado con información morfosintáctica.\n",
        "\n",
        "* Dividir el corpus en dos partes: training (el 90% de las primeras frases) y de test (el 10% restante)\n",
        "* Reducir el conjunto de etiquetas morfosintácticas del corpus (289) a un conjunto reducido(67). Para ello, considerar las etiquetas de longitud =2 salvo los verbos (v) y los signos de puntuación (F) que pueden ser de tres. También pueden existir etiquetas de longitud =1. Eliminar también las tuplas vacias, por ejemplo: (u'*0*', u'sn'), son tuplas que el primer elemento tiene el valor '*0*'.\n",
        "\n",
        ">Nota: para entender el significado de las etiquetas se puede consultar el siguiente enlace: https://freeling-user-manual.readthedocs.io/en/latest/tagsets/tagset-es/\n",
        "\n",
        "Ejemplo de lo que se pide:\n",
        "* original\n",
        "```\n",
        "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n",
        "```\n",
        "* nuevo\n",
        "```\n",
        "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'fpa'), ('EDF', 'np'), ('-Fpt-', 'fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'fc'), ('jueves', 'w'), (',', 'fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'fpa'), ('EAA', 'np'), ('-Fpt-', 'fpt'), (',', 'fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vmn'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'z'), ('megavatios', 'nc'), ('.', 'fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vmi'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'fc'), ('prevé', 'vmm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'sp'), ('funcionar', 'vmn'), ('en', 'sp'), ('mayo_del_2002', 'w'), ('.', 'fp')]]\n",
        "```\n",
        "* opcional:\n",
        "    * número de frases: 6030\n",
        "    * número de palabras: 192686\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb",
      "metadata": {
        "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1958cdd1",
      "metadata": {
        "id": "1958cdd1",
        "outputId": "55c14e6a-912b-4d5d-f15b-8e8f0afb0ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> cess_esp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package cess_esp to /root/nltk_data...\n",
            "      Unzipping corpora/cess_esp.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Descargar el corpus\n",
        "#1. ejecutar esta linea\n",
        "nltk.download()\n",
        "#2. elegir la opción d) Download\n",
        "#3. escribir identificador del corpus que deseamos, en nuestro caso 'cess_esp', 'punkt'... o bien 'all'\n",
        "#4. q) quit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fe24a7cb",
      "metadata": {
        "id": "fe24a7cb",
        "outputId": "d3ae4da0-421d-4d09-e479-c372586863c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras 3 frases del corpus original:\n",
            "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
            "[('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]\n",
            "[('La', 'da0fs0'), ('electricidad', 'ncfs000'), ('producida', 'aq0fsp'), ('pasará', 'vmif3s0'), ('a', 'sps00'), ('la', 'da0fs0'), ('red', 'ncfs000'), ('eléctrica', 'aq0fs0'), ('pública', 'aq0fs0'), ('de', 'sps00'), ('México', 'np00000'), ('en_virtud_de', 'sps00'), ('un', 'di0ms0'), ('acuerdo', 'ncms000'), ('de', 'sps00'), ('venta', 'ncfs000'), ('de', 'sps00'), ('energía', 'ncfs000'), ('de', 'sps00'), ('EAA', 'np00000'), ('con', 'sps00'), ('la', 'da0fs0'), ('Comisión_Federal_de_Electricidad', 'np00000'), ('-Fpa-', 'Fpa'), ('CFE', 'np00000'), ('-Fpt-', 'Fpt'), ('por', 'sps00'), ('una', 'di0fs0'), ('duración', 'ncfs000'), ('de', 'sps00'), ('25', 'Z'), ('años', 'ncmp000'), ('.', 'Fp')]\n",
            "[('El', 'OTHER'), ('grupo', 'OTHER'), ('estatal', 'OTHER'), ('Electricité_de_France', 'OTHER'), ('-Fpa-', 'Fpa'), ('EDF', 'OTHER'), ('-Fpt-', 'Fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'OTHER'), ('compra', 'OTHER'), ('del', 'OTHER'), ('51_por_ciento', 'Zp'), ('de', 'OTHER'), ('la', 'OTHER'), ('empresa', 'OTHER'), ('mexicana', 'OTHER'), ('Electricidad_Águila_de_Altamira', 'OTHER'), ('-Fpa-', 'Fpa'), ('EAA', 'OTHER'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'OTHER'), ('por', 'OTHER'), ('el', 'OTHER'), ('japonés', 'OTHER'), ('Mitsubishi_Corporation', 'OTHER'), ('para', 'OTHER'), ('poner_en_marcha', 'vmn'), ('una', 'OTHER'), ('central', 'OTHER'), ('de', 'OTHER'), ('gas', 'OTHER'), ('de', 'OTHER'), ('495', 'Z'), ('megavatios', 'OTHER'), ('.', 'Fp')]\n",
            "[('Una', 'OTHER'), ('portavoz', 'OTHER'), ('de', 'OTHER'), ('EDF', 'OTHER'), ('explicó', 'vmi'), ('a', 'OTHER'), ('EFE', 'OTHER'), ('que', 'cs'), ('el', 'OTHER'), ('proyecto', 'OTHER'), ('para', 'OTHER'), ('la', 'OTHER'), ('construcción', 'OTHER'), ('de', 'OTHER'), ('Altamira_2', 'OTHER'), (',', 'Fc'), ('al', 'OTHER'), ('norte', 'OTHER'), ('de', 'OTHER'), ('Tampico', 'OTHER'), (',', 'Fc'), ('prevé', 'vmm'), ('la', 'OTHER'), ('utilización', 'OTHER'), ('de', 'OTHER'), ('gas', 'OTHER'), ('natural', 'OTHER'), ('como', 'cs'), ('combustible', 'OTHER'), ('principal', 'OTHER'), ('en', 'OTHER'), ('una', 'OTHER'), ('central', 'OTHER'), ('de', 'OTHER'), ('ciclo', 'OTHER'), ('combinado', 'OTHER'), ('que', 'OTHER'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'OTHER'), ('funcionar', 'vmn'), ('en', 'OTHER'), ('mayo_del_2002', 'W'), ('.', 'Fp')]\n",
            "[('La', 'OTHER'), ('electricidad', 'OTHER'), ('producida', 'OTHER'), ('pasará', 'vmi'), ('a', 'OTHER'), ('la', 'OTHER'), ('red', 'OTHER'), ('eléctrica', 'OTHER'), ('pública', 'OTHER'), ('de', 'OTHER'), ('México', 'OTHER'), ('en_virtud_de', 'OTHER'), ('un', 'OTHER'), ('acuerdo', 'OTHER'), ('de', 'OTHER'), ('venta', 'OTHER'), ('de', 'OTHER'), ('energía', 'OTHER'), ('de', 'OTHER'), ('EAA', 'OTHER'), ('con', 'OTHER'), ('la', 'OTHER'), ('Comisión_Federal_de_Electricidad', 'OTHER'), ('-Fpa-', 'Fpa'), ('CFE', 'OTHER'), ('-Fpt-', 'Fpt'), ('por', 'OTHER'), ('una', 'OTHER'), ('duración', 'OTHER'), ('de', 'OTHER'), ('25', 'Z'), ('años', 'OTHER'), ('.', 'Fp')]\n"
          ]
        }
      ],
      "source": [
        "#Esta linea carga el corpus en castellano, pero podemos hacerlo en ingles o catalan si os apetece\n",
        "from nltk.corpus import cess_esp\n",
        "corpus_sentences=cess_esp.tagged_sents()\n",
        "\n",
        "# Mostrar las 3 primeras frases del corpus original\n",
        "print(\"Primeras 3 frases del corpus original:\")\n",
        "for sentence in corpus_sentences[:3]:\n",
        "    print(sentence)\n",
        "\n",
        "# 1. Dividir el corpus en 90% entrenamiento y 10% test\n",
        "train_size = int(0.9 * len(corpus_sentences))\n",
        "train_sentences = corpus_sentences[:train_size]\n",
        "test_sentences = corpus_sentences[train_size:]\n",
        "\n",
        "#opcional: calculamos el número de sentencias y palabras del corpus y los mostramos.\n",
        "\n",
        "#mostramos las 3 primeras frases del corpus (como está originalmente en el enunciado)\n",
        "\n",
        "#Escribir el corpus en un fichero\n",
        "with open('corpus.txt', 'w', encoding='utf-8') as f:\n",
        "    for sentence in corpus_sentences:\n",
        "        for word, tag in sentence:\n",
        "            f.write(f\"{word}\\t{tag}\\n\")\n",
        "\n",
        "\n",
        "#Leer el corpus de un fichero y guardalo en una lista\n",
        "lista=[]\n",
        "with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, tag = line.strip().split('\\t')\n",
        "        lista.append((word, tag))\n",
        "\n",
        "\n",
        "#Definimos una funcion auxiliar (getLabel) que a partir de una etiqueta, la reduzca a su nueva versión siguiendo las instrucciones del enunciado\n",
        "def getLabel(tag):\n",
        "    if tag.startswith('v'):  # Verbos\n",
        "        return tag[:3]  # Conservar los 3 primeros caracteres\n",
        "    elif tag.startswith('F'):  # Signos de puntuación\n",
        "        return tag[:3]  # Conservar los 3 primeros caracteres\n",
        "    elif len(tag) == 2:  # Etiquetas de longitud 2\n",
        "        return tag[:2]  # Conservar los 2 primeros caracteres\n",
        "    elif len(tag) == 1:  # Etiquetas de longitud 1\n",
        "        return tag  # Mantener igual\n",
        "    return 'OTHER'  # Para cualquier otro caso\n",
        "\n",
        "# 3. Eliminar tuplas vacías\n",
        "def clean_corpus(sentences):\n",
        "  return [\n",
        "      [(word, getLabel(tag)) for word, tag in sentence if word != '*0*']\n",
        "      for sentence in sentences\n",
        "  ]\n",
        "\n",
        "# 4. Limpiar y reducir etiquetas para el conjunto de entrenamiento y test\n",
        "train_sentences_cleaned = clean_corpus(train_sentences)\n",
        "test_sentences_cleaned = clean_corpus(test_sentences)\n",
        "\n",
        "\n",
        "#Definimos un array retic. A continuación leeremos todo el corpus, para cada etiqueta la procesaremos con getLabel y la guardaremos en retic.\n",
        "retic=[]\n",
        "with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, tag = line.strip().split('\\t')\n",
        "        retic.append((word, getLabel(tag)))\n",
        "\n",
        "#mostramos las 3 primeras frases del corpus con las etiquetas reducidas (como muestra el enunciado)\n",
        "for sentence in train_sentences_cleaned[:3]:\n",
        "    print(sentence)\n",
        "\n",
        "# ESTA MAL!!!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35dee72f",
      "metadata": {
        "id": "35dee72f"
      },
      "source": [
        "### b) Uso de etiquetadores morfosintácticos (hmm o tnt).\n",
        "* Entrenar los etiquetadores con la partición de train previamente construida mostrar la precisión:\n",
        "\n",
        "```\n",
        "precisión hmm: 0.8784427571832664\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faa3b76",
      "metadata": {
        "id": "5faa3b76"
      },
      "outputs": [],
      "source": [
        "#definimos la parte de corpus de entramiento (train 90%) y la parte de corpus de test (test 10%)\n",
        "\n",
        "#importamos el etiquetador hmm o tnt, lo entrenamos y mostramos su precisión (accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bae1bb",
      "metadata": {
        "id": "f4bae1bb"
      },
      "source": [
        "### c) Etiquetar con dicho modelo el conjunto de test construido\n",
        "* Evaluar las prestaciones sobre el conjunto de test\n",
        "* Hacer una evaluación de las prestaciones de etiquetado usando todo el corpus (10-fold cross validation).\n",
        "\n",
        "```\n",
        "Media de la precisión de los 10 KFolds:  0.9580362988365326\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a63aade-6345-48f4-b559-d78f275ee306",
      "metadata": {
        "id": "3a63aade-6345-48f4-b559-d78f275ee306"
      },
      "outputs": [],
      "source": [
        "#importamos scikit-learn y mostramos la versión para comprobar que todo funcione bien.\n",
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be17685-3072-4bc9-821d-0115b69f9713",
      "metadata": {
        "scrolled": true,
        "id": "1be17685-3072-4bc9-821d-0115b69f9713"
      },
      "outputs": [],
      "source": [
        "#Montamos el kfold de 10 splits sin shuffle y sin random_state\n",
        "#Para cada KFold guardamos su accuracy, y finalmente mostramos la media de los 10.\n",
        "from sklearn.model_selection import KFold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0",
      "metadata": {
        "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0"
      },
      "source": [
        "### d) Tokenizar una frase y etiquetarla con el modelo entrenado previamente\n",
        "* Usar word_tokenize y tag del modelo usado (tnt, hmm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fab5ad-d2c8-4672-8453-f11d0739d32b",
      "metadata": {
        "id": "26fab5ad-d2c8-4672-8453-f11d0739d32b"
      },
      "outputs": [],
      "source": [
        "#Usar el tokenizador de nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b71a91-6d42-4673-ba93-face2dddef5a",
      "metadata": {
        "id": "44b71a91-6d42-4673-ba93-face2dddef5a"
      },
      "source": [
        "### e) De manera opcional puedes probar a cambiar el idioma, el corpus y ver si afecta mucho a la precisión de los modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3",
      "metadata": {
        "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974",
      "metadata": {
        "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974"
      },
      "source": [
        "### f) Entrega este notebook completado (asegurate que funciona correctamente, y renombralo añadiendo tu nombre y apellidos al final) en la tarea de AULES de la unidad 3."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}